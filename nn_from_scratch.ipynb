{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjgmEvFKiHAb"
   },
   "source": [
    "## Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to build a neural network from scratch!!\n",
    "This exercise will help you understand how neural network works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this we will be implementing the following steps:\n",
    "##### 1.Initialise the parameters(weights and biases)\n",
    "##### 2.Define forward propogation\n",
    "##### 3.Define backward propagation\n",
    "##### 4.Define fit function\n",
    "##### 5.Define predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "u1ETel4j6EZU"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating the data to train and test the model.since we are building a simple neural network, I decided to go with a simple \n",
    "data.If you look closely this is the full adder input which build using logic gates and the output is the sum of the full adder\n",
    "circuit.\n",
    "\"\"\"\n",
    "X = np.array([[0,1,0],\n",
    "                      [0,0,1],\n",
    "                      [1,0,0],\n",
    "                      [1,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,1],\n",
    "                      [0,1,0]])\n",
    "y = np.array([[1,\n",
    "                    0,\n",
    "                    0,\n",
    "                    1,\n",
    "                    1,\n",
    "                    0,\n",
    "                    1]])\n",
    "y = labels.reshape(7,1) #to convert labels to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "URc9j-TUYbdE",
    "outputId": "d1f89860-a9cf-4321-89f7-62aab3650ec9"
   },
   "source": [
    "### 1. Initialise weights\n",
    "\n",
    "For any neural network to learn and improve the two most important parameters required are:Weights and bias.These parameters are\n",
    "then changed by the network according to the data with the aim of reducing the loss/cost function so that model has good acccuracy and performance.\n",
    "For the initial step the weights are initialised randomly rather than intialising them as 0.\n",
    "Initialisation of the weights and bias depends on the layer of your network usually the size of the weights(W1) for the first layer in the network in (the no. of columns/features in the training set,the number of neurons in the next hidden layer) in this case since the training data has 3 columns the size will be (3,2).It is not compulsory for you to chose 2 as the number of neurons in \n",
    "the hidden layer it can be any number.\n",
    "\n",
    "Size of the bias(b1) in the first layer will be (the number of neurons in the next layer,)\n",
    "\n",
    "Size of the weight(W2) in the second/hidden layer will be (the number of neurons in the next layer,the number of neurons/classes in the output layer)\n",
    "\n",
    "If you are solving a binary-classification problem like this example then usually your output layer will have one neuron that can hold value 1 or zero.The number of neurons in the last layer changes according to the problem.\n",
    "\n",
    "Size of the bias(b2) of the second layer: (the number of neurons/classes in the output layer,)\n",
    "\n",
    "After intialising we will store these weights and bias in a dictionary that can be used later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layers=[]):\n",
    "        params={}\n",
    "        np.random.seed(1) # Seed the random number generator\n",
    "        params[\"W1\"] = np.random.randn(layers[0], layers[1]) \n",
    "        params['b1']  =np.random.randn(layers[1],)\n",
    "        params['W2'] = np.random.randn(layers[1],layers[2]) \n",
    "        params['b2'] = np.random.randn(layers[2],)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.62434536, -0.61175641],\n",
       "        [-0.52817175, -1.07296862],\n",
       "        [ 0.86540763, -2.3015387 ]]),\n",
       " 'b1': array([ 1.74481176, -0.7612069 ]),\n",
       " 'W2': array([[ 0.3190391 ],\n",
       "        [-0.24937038]]),\n",
       " 'b2': array([1.46210794])}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params=init_weights(layers=[3,2,1])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define forward propagation\n",
    "\n",
    "In order to understand how we can define a forward propagation we have to first understand how a neural network works.Intially the weights and bias are intialised then these parameters are used to calculate a quantity usually refered as Z.\n",
    "                                     Z= W*X+b\n",
    "                                     where W= weights,X=input,b=bias\n",
    "Once the Z is computed then it is passed through an activation functions.\n",
    "                                   A1=activation(Z)\n",
    "There are many types of activation functions such as relu,tanh,sigmoid,softmax.Usually relu/tanh are used in the hidden layers where as softmax/sigmoid are used in the last/output layer. This process is repeated till we reach the last layer where the output is calculated.After calculating output a loss function is used to calculate the loss of the model.This loss is then used in backpropagation to change the weights and bias such that the loss function reduces.</h4>\n",
    "\n",
    "<h3>Here's a gif to help you visualise the working of a neural network:\n",
    "![nnworking](https://miro.medium.com/max/3000/1*bhFifratH9DjKqMBTeQG5A.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to give a rough overview of how a neural network works.If you want to get a deeper understanding about the network, you can read this article : <i>https://medium.com/@purnasaigudikandula/a-beginner-intro-to-neural-networks-543267bda3c8 </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "        '''\n",
    "        The ReLufunction performs a threshold\n",
    "        operation to each input element where values less \n",
    "        than zero are set to zero.\n",
    "        '''\n",
    "        return np.maximum(0, Z)\n",
    "        \n",
    "        \n",
    "def sigmoid(Z):\n",
    "        '''\n",
    "        The sigmoid function takes in real numbers in any range and \n",
    "        squashes it to a real-valued output between 0 and 1.\n",
    "        '''\n",
    "        return 1.0 / (1.0 + np.exp(-Z))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {
    "download.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since loss function plays an important role in imporving the accuracy of the model it is important to choose the correct type of loss function that can be used to esitmate the performance of the model.For classification problem we usually use cross_entropy as our loss function where as for regression problems we use mean square error or other regression losses.\n",
    "\n",
    "Formula of cross_entropy: \n",
    "![download.png](attachment:download.png)\n",
    "\n",
    "\n",
    "This formula is implemented in the entropy_loss function that takes actual output and predicted output as inputs and calculates the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_loss(y, yhat):\n",
    "        nsample = len(y)\n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat), y) + np.multiply((1 - y), np.log(1 - yhat))))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation will take in inputs(X,y) and then return the predicted output and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,y):\n",
    "        '''\n",
    "        Performs the forward propagation\n",
    "        '''\n",
    "        \n",
    "        Z1 = X.dot(params['W1']) + params['b1']\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = A1.dot(params['W2']) + params['b2']\n",
    "        yhat = sigmoid(Z2)\n",
    "        loss = entropy_loss(y,yhat)\n",
    "\n",
    "        # save calculated parameters     \n",
    "        params['Z1'] = Z1\n",
    "        params['Z2'] = Z2\n",
    "        params['A1'] = A1\n",
    "\n",
    "        return yhat,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0990247935590556"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat,loss=forward_propagation(X,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Define backpropagation\n",
    "Now we have the loss from the forward propagation.Let's use backpropagation to reduce the loss and imporve the performance.\n",
    "It is little tricky to understand how back propagation works, in layman terms we start from the output layer change the weights and bias of that layer and then move into the hidden layer change those values wrt to the out layer weights and bias.Repeat this till we reach the input layer.\n",
    "\n",
    "If you know calculus then the backpropagation is mainly done by computing the derivative of loss wrt weights,bias and activation function.This is done as a derivative will tell how much the loss function changes when we change the weights and bias.In backpropagation the derivative is computed using a rule called chain rule.\n",
    "\n",
    "Here's an article that you can read to understand how these derivates are calculated: \n",
    "<i>https://medium.com/@pdquant/all-the-backpropagation-derivatives-d5275f727f60</i>\n",
    "\n",
    "#### Visualise backpropagation:\n",
    "\n",
    "\n",
    "![backpropagation](https://mlfromscratch.com/content/images/2019/12/overview-nn-optimized.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X,y,yhat):\n",
    "        '''\n",
    "        Computes the derivatives and update weights and bias according.\n",
    "        '''\n",
    "        learning_rate=0.01\n",
    "        def dRelu(x):\n",
    "            x[x<=0] = 0\n",
    "            x[x>0] = 1\n",
    "            return x\n",
    "        \n",
    "        dl_wrt_yhat = -(np.divide(y,yhat) - np.divide((1 - y),(1-yhat)))\n",
    "        dl_wrt_sig = yhat * (1-yhat)\n",
    "        dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "        dl_wrt_A1 = dl_wrt_z2.dot(params['W2'].T)\n",
    "        dl_wrt_w2 = params['A1'].T.dot(dl_wrt_z2)\n",
    "        dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0)\n",
    "\n",
    "        dl_wrt_z1 = dl_wrt_A1 * dRelu(params['Z1'])\n",
    "        dl_wrt_w1 =X.T.dot(dl_wrt_z1)\n",
    "        dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0)\n",
    "\n",
    "        #update the weights and bias\n",
    "        params['W1'] = params['W1'] - learning_rate * dl_wrt_w1\n",
    "        params['W2'] = params['W2'] - learning_rate * dl_wrt_w2\n",
    "        params['b1'] = params['b1'] - learning_rate * dl_wrt_b1\n",
    "        params['b2'] =params['b2'] - learning_rate * dl_wrt_b2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a fit function\n",
    "\n",
    "Now we are implemented foward and backward propagation seperately.It is time for us to combine them and call them recursively.This is done using a fit function.Fit function usually runs for certain number of time ,this number is usually called epochs.One epoch means passing the entire data one time to model.\n",
    "\n",
    "For this example I ran the training data for 200 epochs and each time I called the forward_propagation got the predicted value vector and loss value.Passed that value to backpropagation, here the weights and bias are updated in order to reduce the loss function.To monitor how the loss is changing in each epoch I used a list to store the loss value after each iteration.Later I print those loss values to see if the loss is decreasing or increasing after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    Loss=[]\n",
    "\n",
    "    for i in range(100):\n",
    "        yhat, loss = forward_propagation(X,y)\n",
    "        back_propagation(X,y,yhat)\n",
    "        \n",
    "        Loss.append(loss)\n",
    "        \n",
    "       \n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3511467444665201, 0.34994519653375106, 0.3487459637961401, 0.3475490571901554, 0.346354486837742, 0.34516226207581696, 0.3440326043633848, 0.34310081455800356, 0.3421799848081703, 0.3412687025385637, 0.3403657190031814, 0.33946993122712726, 0.33858036581262213, 0.33769616443927136, 0.3368165708998287, 0.3359409195240859, 0.3350686248548307, 0.3341991724508379, 0.333332110702462, 0.332467043555476, 0.3316036240482973, 0.33074154857661114, 0.3298805518076456, 0.32902040217396444, 0.32816089788363606, 0.32730186339004436, 0.3264431462704434, 0.3255846144676733, 0.3247261538542585, 0.3238676660824716, 0.3230090666878634, 0.32215028341730045, 0.32129125475572196, 0.3204319286286862, 0.3195722612603173, 0.31871221616855955, 0.317851763281674, 0.31699087816174404, 0.3161295413225674, 0.3152677376307674, 0.3144054557802367, 0.3135426878311653, 0.31267942880592886, 0.3118156763350075, 0.31095143034690204, 0.31008669279673023, 0.3092214674288056, 0.30835575956905886, 0.3074895759436536, 0.3066229245205821, 0.30575581437140836, 0.3048882555506684, 0.30402025899073215, 0.30315183641020255, 0.3022830002341504, 0.3014137635246997, 0.3005441399206511, 0.2996741435849955, 0.29880378915930605, 0.2979330917241268, 0.2970620667645776, 0.2961907301404961, 0.29531909806052054, 0.2944471870595895, 0.29357501397940106, 0.29270259595143167, 0.2918299503821644, 0.2909570949402195, 0.2900840475451186, 0.289210826357454, 0.2883374497702515, 0.28746393640135576, 0.28659030508667843, 0.2857165748741765, 0.2848427650184435, 0.2839688949758094, 0.2830949843998623, 0.28222105313731466, 0.2813471212241461, 0.28047320888196703, 0.2795993365145509, 0.278725524704495, 0.2778517942099689, 0.27697816596152286, 0.2761046610589245, 0.2752313007680049, 0.2743581065174912, 0.27348509989580966, 0.27261230264784553, 0.2717397366716468, 0.27086742401506414, 0.26999538687231545, 0.2691236475804721, 0.2682522286158581, 0.2673811525903616, 0.2665104422476529, 0.2656401204593065, 0.26477021022082986, 0.2639007346475915, 0.2630317169706544]\n"
     ]
    }
   ],
   "source": [
    "loss=fit(X,y)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise loss function\n",
    "\n",
    "This is a small plot function I wrote to help me visualise the function after every iteration.The X-value denotes the number of iterations/epochs and the y-value denotes the loss at that particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(loss):\n",
    "    plt.plot(loss)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Visualisation')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Function\n",
    "\n",
    "Finally!!\n",
    "After implementing the fit function and visualising the loss function.Its time to test our model!\n",
    "We will give a similar input to the model and check if it's giving correct output or not.\n",
    "\n",
    "The predict function calculates the Z1,a1,Z2 and y_pred values similar to the way it is calculated in the forward_propagation.As we are saving the weights and bias updates in the params dictionary initialised earlier.When we call those values,we are in turn using the updated weights and bias.\n",
    "\n",
    "To test our model I have passed the input =[0,0,0] which it has never seen before!The correct output of this input is 0.\n",
    "Let's find out what our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_value):\n",
    "    Z1=np.dot(input_value,params[\"W1\"])+params[\"b1\"]\n",
    "    a1=relu(Z1)\n",
    "    Z2=np.dot(a1,params[\"W2\"])+params[\"b2\"]\n",
    "    y_pred=sigmoid(Z2)\n",
    "    return np.round(y_pred,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=predict([0,0,0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yay!We got the correct output.This shows that our model has good performance.This is a very basic implementation of a neural network.A deeper neural network with many layers and parameters can be implemented to solve real world problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I would encourage all of you to implement a similar neural network on your own and train it on your own data and test it's performance.This will help you to get a deeper insight about how a neural network works and how it can be build from scratch without using any pre-build functions from keras or tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nn-from-scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
